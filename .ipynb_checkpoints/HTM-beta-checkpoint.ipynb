{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from itertools import islice\n",
    "import json\n",
    "import os\n",
    "from pkg_resources import resource_filename\n",
    "\n",
    "from nupic.data.file_record_stream import FileRecordStream\n",
    "from nupic.engine import Network\n",
    "from nupic.encoders import MultiEncoder, ScalarEncoder, DateEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "_VERBOSITY = 0\n",
    "_NUM_RECORDS = 153501\n",
    "\n",
    "# Default config fields for SPRegion\n",
    "_SP_PARAMS = {\n",
    "    \"spVerbosity\": _VERBOSITY,\n",
    "    \"spatialImp\": \"cpp\",\n",
    "    \"globalInhibition\": 1,\n",
    "    \"columnCount\": 2048,\n",
    "    \"inputWidth\": 0,\n",
    "    \"numActiveColumnsPerInhArea\": 40,\n",
    "    \"seed\": 1956,\n",
    "    \"potentialPct\": 0.8,\n",
    "    \"synPermConnected\": 0.1,\n",
    "    \"synPermActiveInc\": 0.0001,\n",
    "    \"synPermInactiveDec\": 0.0005,\n",
    "    \"boostStrength\": 0.0,\n",
    "}\n",
    "\n",
    "# Default config fields for TPRegion\n",
    "_TM_PARAMS = {\n",
    "    \"verbosity\": _VERBOSITY,\n",
    "    \"columnCount\": 2048,\n",
    "    \"cellsPerColumn\": 32,\n",
    "    \"inputWidth\": 2048,\n",
    "    \"seed\": 1960,\n",
    "    \"temporalImp\": \"cpp\",\n",
    "    \"newSynapseCount\": 20,\n",
    "    \"maxSynapsesPerSegment\": 32,\n",
    "    \"maxSegmentsPerCell\": 128,\n",
    "    \"initialPerm\": 0.21,\n",
    "    \"permanenceInc\": 0.1,\n",
    "    \"permanenceDec\": 0.1,\n",
    "    \"globalDecay\": 0.0,\n",
    "    \"maxAge\": 0,\n",
    "    \"minThreshold\": 9,\n",
    "    \"activationThreshold\": 12,\n",
    "    \"outputType\": \"normal\",\n",
    "    \"pamLength\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTemporalAnomaly(recordParams, spatialParams=_SP_PARAMS,\n",
    "                          temporalParams=_TM_PARAMS,\n",
    "                          verbosity=_VERBOSITY):\n",
    "\n",
    "    \"\"\"Generates a Network with connected RecordSensor, SP, TM.\n",
    "    This function takes care of generating regions and the canonical links.\n",
    "    The network has a sensor region reading data from a specified input and\n",
    "    passing the encoded representation to an SPRegion.\n",
    "    The SPRegion output is passed to a TMRegion.\n",
    "    Note: this function returns a network that needs to be initialized. This\n",
    "    allows the user to extend the network by adding further regions and\n",
    "    connections.\n",
    "    :param recordParams: a dict with parameters for creating RecordSensor region.\n",
    "    :param spatialParams: a dict with parameters for creating SPRegion.\n",
    "    :param temporalParams: a dict with parameters for creating TMRegion.\n",
    "    :param verbosity: an integer representing how chatty the network will be.\n",
    "    \"\"\"\n",
    "    inputFilePath = recordParams[\"inputFilePath\"]\n",
    "    scalarEncoder1Args = recordParams[\"scalarEncoder1Args\"]\n",
    "    scalarEncoder2Args = recordParams[\"scalarEncoder2Args\"]\n",
    "    scalarEncoder3Args = recordParams[\"scalarEncoder3Args\"]\n",
    "    dateEncoderArgs = recordParams[\"dateEncoderArgs\"]\n",
    "\n",
    "    scalarEncoder1 = ScalarEncoder(**scalarEncoder1Args)\n",
    "    scalarEncoder2 = ScalarEncoder(**scalarEncoder2Args)\n",
    "    scalarEncoder3 = ScalarEncoder(**scalarEncoder3Args)\n",
    "    dateEncoder = DateEncoder(**dateEncoderArgs)\n",
    "\n",
    "    encoder = MultiEncoder()\n",
    "    encoder.addEncoder(scalarEncoder1Args[\"name\"], scalarEncoder1)\n",
    "    encoder.addEncoder(scalarEncoder2Args[\"name\"], scalarEncoder2)\n",
    "    encoder.addEncoder(scalarEncoder3Args[\"name\"], scalarEncoder3)\n",
    "    encoder.addEncoder(dateEncoderArgs[\"name\"], dateEncoder)\n",
    "\n",
    "    network = Network()\n",
    "\n",
    "    network.addRegion(\"sensor\", \"py.RecordSensor\",\n",
    "                    json.dumps({\"verbosity\": verbosity}))\n",
    "\n",
    "    sensor = network.regions[\"sensor\"].getSelf()\n",
    "    sensor.encoder = encoder\n",
    "    sensor.dataSource = FileRecordStream(streamID=inputFilePath)\n",
    "\n",
    "    # Create the spatial pooler region\n",
    "    spatialParams[\"inputWidth\"] = sensor.encoder.getWidth()\n",
    "    network.addRegion(\"spatialPoolerRegion\", \"py.SPRegion\",\n",
    "                      json.dumps(spatialParams))\n",
    "\n",
    "    # Link the SP region to the sensor input\n",
    "    network.link(\"sensor\", \"spatialPoolerRegion\", \"UniformLink\", \"\")\n",
    "    network.link(\"sensor\", \"spatialPoolerRegion\", \"UniformLink\", \"\",\n",
    "                 srcOutput=\"resetOut\", destInput=\"resetIn\")\n",
    "    network.link(\"spatialPoolerRegion\", \"sensor\", \"UniformLink\", \"\",\n",
    "                 srcOutput=\"spatialTopDownOut\", destInput=\"spatialTopDownIn\")\n",
    "    network.link(\"spatialPoolerRegion\", \"sensor\", \"UniformLink\", \"\",\n",
    "                 srcOutput=\"temporalTopDownOut\", destInput=\"temporalTopDownIn\")\n",
    "\n",
    "    # Add the TPRegion on top of the SPRegion\n",
    "    network.addRegion(\"temporalPoolerRegion\", \"py.TMRegion\",\n",
    "                      json.dumps(temporalParams))\n",
    "\n",
    "    network.link(\"spatialPoolerRegion\", \"temporalPoolerRegion\", \"UniformLink\", \"\")\n",
    "    network.link(\"temporalPoolerRegion\", \"spatialPoolerRegion\", \"UniformLink\", \"\",\n",
    "                 srcOutput=\"topDownOut\", destInput=\"topDownIn\")\n",
    "\n",
    "    spatialPoolerRegion = network.regions[\"spatialPoolerRegion\"]\n",
    "\n",
    "    # Make sure learning is enabled\n",
    "    spatialPoolerRegion.setParameter(\"learningMode\", True)\n",
    "    # We want temporal anomalies so disable anomalyMode in the SP. This mode is\n",
    "    # used for computing anomalies in a non-temporal model.\n",
    "    spatialPoolerRegion.setParameter(\"anomalyMode\", False)\n",
    "\n",
    "    temporalPoolerRegion = network.regions[\"temporalPoolerRegion\"]\n",
    "\n",
    "    # Enable topDownMode to get the predicted columns output\n",
    "    temporalPoolerRegion.setParameter(\"topDownMode\", True)\n",
    "    # Make sure learning is enabled (this is the default)\n",
    "    temporalPoolerRegion.setParameter(\"learningMode\", True)\n",
    "    # Enable inference mode so we get predictions\n",
    "    temporalPoolerRegion.setParameter(\"inferenceMode\", True)\n",
    "    # Enable anomalyMode to compute the anomaly score.\n",
    "    temporalPoolerRegion.setParameter(\"anomalyMode\", True)\n",
    "\n",
    "    return network\n",
    "\n",
    "def getDate(recordParams, total = _NUM_RECORDS):\n",
    "    inputFilePath = recordParams[\"inputFilePath\"]\n",
    "    date = []\n",
    "    with open(inputFilePath) as fin:\n",
    "        reader = csv.reader(fin)\n",
    "        headers = reader.next()  # skip the header\n",
    "        reader.next()\n",
    "        reader.next()\n",
    "        for record in islice(reader, total):\n",
    "            Record_in_Dict = dict(zip(headers, record))\n",
    "            date.append(Record_in_Dict[\"time\"])\n",
    "    return date\n",
    "    \n",
    "def runNetwork(network, date):\n",
    "    \"\"\"Run the network and write output to writer.\n",
    "    :param network: a Network instance to run\n",
    "    :param writer: a csv.writer instance to write output to\n",
    "    \"\"\"\n",
    "    sensorRegion = network.regions[\"sensor\"]\n",
    "    temporalPoolerRegion = network.regions[\"temporalPoolerRegion\"]\n",
    "\n",
    "    for i in xrange(_NUM_RECORDS):\n",
    "      # Run the network for a single iteration\n",
    "        network.run(1)\n",
    "      # Write out the anomaly score along with the record number and consumption\n",
    "      # value.\n",
    "        anomalyScore = temporalPoolerRegion.getOutputData(\"anomalyScore\")[0]\n",
    "        pre1 = sensorRegion.getOutputData(\"sourceOut\")[0]\n",
    "        pre2 = sensorRegion.getOutputData(\"sourceOut\")[1]\n",
    "        pre3 = sensorRegion.getOutputData(\"sourceOut\")[2]\n",
    "        if anomalyScore > 0.5:\n",
    "            print \"Date: \", date[i], \"\\t Anomaly Score: \", anomalyScore, \"\\t Record: \", (pre1, pre2, pre3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  2018-10-12 23:00:00 \t Anomaly Score:  1.0 \t Record:  (0.97471839, -0.0020643491, -0.012584261)\n",
      "Date:  2018-10-12 23:00:03 \t Anomaly Score:  1.0 \t Record:  (0.97426432, -0.0017743616, -0.012833592)\n",
      "Date:  2018-10-12 23:00:06 \t Anomaly Score:  1.0 \t Record:  (0.97439432, -0.0014845898, -0.012953289)\n",
      "Date:  2018-10-14 17:40:51 \t Anomaly Score:  0.8 \t Record:  (1.0391942, -0.093815915, -0.018842492)\n",
      "Date:  2018-10-14 17:40:54 \t Anomaly Score:  1.0 \t Record:  (0.99482751, -0.0099751307, -0.016540349)\n",
      "Date:  2018-10-14 17:41:00 \t Anomaly Score:  0.65 \t Record:  (1.0030808, -0.024703523, -0.019204004)\n",
      "Date:  2018-10-14 17:42:18 \t Anomaly Score:  0.95 \t Record:  (0.95212471, 0.071246013, -0.011715979)\n",
      "Date:  2018-10-14 17:42:21 \t Anomaly Score:  1.0 \t Record:  (0.99239528, -0.0071764751, -0.016137412)\n",
      "Date:  2018-10-14 17:42:57 \t Anomaly Score:  0.775 \t Record:  (0.99018824, 0.00023202355, -0.017626982)\n",
      "Date:  2018-10-14 17:43:39 \t Anomaly Score:  0.825 \t Record:  (1.0513414, -0.11542323, -0.021697162)\n",
      "Date:  2018-10-15 03:33:06 \t Anomaly Score:  0.55 \t Record:  (0.95770133, 0.056052748, -0.017765524)\n",
      "Date:  2018-10-15 03:33:09 \t Anomaly Score:  1.0 \t Record:  (0.98987985, -0.0059551685, -0.015021263)\n",
      "Date:  2018-10-15 16:25:54 \t Anomaly Score:  0.975 \t Record:  (0.93834323, 0.10455234, -0.0079674264)\n",
      "Date:  2018-10-15 16:25:57 \t Anomaly Score:  1.0 \t Record:  (0.98926985, -0.00010775141, -0.016698759)\n",
      "Date:  2018-10-15 21:15:12 \t Anomaly Score:  0.55 \t Record:  (1.0163352, -0.06409537, -0.022075506)\n",
      "Date:  2018-10-15 21:15:15 \t Anomaly Score:  0.9 \t Record:  (0.95886779, 0.040313408, -0.012105786)\n",
      "Date:  2018-10-15 21:16:06 \t Anomaly Score:  0.6 \t Record:  (0.94672102, 0.067901284, -0.010719199)\n",
      "Date:  2018-10-15 21:16:09 \t Anomaly Score:  1.0 \t Record:  (0.93792456, 0.084864438, -0.015047588)\n",
      "Date:  2018-10-15 21:16:12 \t Anomaly Score:  1.0 \t Record:  (0.97119898, 0.011483722, -0.020402357)\n",
      "Date:  2018-10-15 21:16:27 \t Anomaly Score:  0.625 \t Record:  (0.95907432, 0.052097384, -0.0098491684)\n",
      "Date:  2018-10-15 21:16:30 \t Anomaly Score:  0.975 \t Record:  (0.99505299, -0.038625143, -0.015636317)\n",
      "Date:  2018-10-15 22:57:42 \t Anomaly Score:  0.725 \t Record:  (1.0613081, -0.16447707, -0.01830316)\n",
      "Date:  2018-10-15 22:57:45 \t Anomaly Score:  1.0 \t Record:  (0.99195224, -0.040245179, -0.013538113)\n",
      "Date:  2018-10-15 22:59:27 \t Anomaly Score:  0.525 \t Record:  (0.95107913, 0.054501832, -0.011256194)\n",
      "Date:  2018-10-15 22:59:30 \t Anomaly Score:  0.975 \t Record:  (1.0077409, -0.05927651, -0.010253411)\n",
      "Date:  2018-10-15 22:59:42 \t Anomaly Score:  0.975 \t Record:  (0.91823053, 0.12297715, -0.012768134)\n",
      "Date:  2018-10-15 22:59:45 \t Anomaly Score:  1.0 \t Record:  (0.95334852, 0.052847229, -0.010221724)\n",
      "Date:  2018-10-15 22:59:48 \t Anomaly Score:  0.65 \t Record:  (1.0345999, -0.11239083, -0.024804136)\n",
      "Date:  2018-10-21 00:44:15 \t Anomaly Score:  0.6 \t Record:  (1.00546, -0.056621064, -0.015525236)\n",
      "Date:  2018-10-21 00:44:18 \t Anomaly Score:  1.0 \t Record:  (0.97413254, 0.0033538844, -0.014584946)\n",
      "Date:  2018-10-21 06:32:03 \t Anomaly Score:  0.65 \t Record:  (0.95063734, 0.078618117, -0.019130709)\n",
      "Date:  2018-10-21 06:32:06 \t Anomaly Score:  1.0 \t Record:  (0.97310448, 0.028678715, -0.016099285)\n",
      "Date:  2018-10-21 16:24:06 \t Anomaly Score:  0.875 \t Record:  (0.94314051, 0.071159057, -0.013788488)\n",
      "Date:  2018-10-21 16:24:30 \t Anomaly Score:  0.55 \t Record:  (0.95607311, 0.054292005, -0.013193848)\n",
      "Date:  2018-10-22 06:30:48 \t Anomaly Score:  0.525 \t Record:  (0.9547438, 0.052648094, -0.013067023)\n",
      "Date:  2018-10-22 06:49:06 \t Anomaly Score:  0.7 \t Record:  (0.94972199, 0.067323819, -0.01569159)\n",
      "Date:  2018-10-22 06:49:09 \t Anomaly Score:  0.95 \t Record:  (0.98799169, -0.0074873189, -0.016211795)\n",
      "Date:  2018-10-23 14:03:00 \t Anomaly Score:  0.825 \t Record:  (0.94848347, 0.085312285, -0.012013675)\n",
      "Date:  2018-10-23 14:03:03 \t Anomaly Score:  1.0 \t Record:  (0.98295546, 0.0096026976, -0.016849782)\n",
      "Date:  2018-10-23 17:40:42 \t Anomaly Score:  0.6 \t Record:  (1.0532575, -0.12531155, -0.022697629)\n",
      "Date:  2018-10-23 17:41:45 \t Anomaly Score:  0.825 \t Record:  (0.95203513, 0.066340901, -0.014674033)\n",
      "Date:  2018-10-23 17:41:48 \t Anomaly Score:  0.95 \t Record:  (1.0605544, -0.14097409, -0.020731224)\n",
      "Date:  2018-10-23 18:41:27 \t Anomaly Score:  1.0 \t Record:  (0.99164605, -0.0095848404, -0.018270243)\n",
      "Date:  2018-10-23 19:17:51 \t Anomaly Score:  0.725 \t Record:  (1.0476398, -0.11859363, -0.022003207)\n",
      "Date:  2018-10-23 19:17:54 \t Anomaly Score:  1.0 \t Record:  (1.0078461, -0.042569902, -0.018212043)\n",
      "Date:  2018-10-23 19:18:12 \t Anomaly Score:  0.575 \t Record:  (1.021588, -0.070215598, -0.01828327)\n",
      "Date:  2018-10-25 01:50:39 \t Anomaly Score:  0.775 \t Record:  (0.94125652, 0.081544913, -0.015977662)\n",
      "Date:  2018-10-25 01:50:42 \t Anomaly Score:  1.0 \t Record:  (0.97908741, -0.00051065988, -0.016288538)\n",
      "Date:  2018-10-25 01:52:24 \t Anomaly Score:  0.65 \t Record:  (0.94650131, 0.05903732, -0.013009754)\n",
      "Date:  2018-10-25 01:54:00 \t Anomaly Score:  0.725 \t Record:  (1.0370903, -0.11382017, -0.020206997)\n",
      "Date:  2018-10-25 01:54:03 \t Anomaly Score:  1.0 \t Record:  (0.97518629, 0.0068786447, -0.014122462)\n",
      "Date:  2018-10-25 01:54:27 \t Anomaly Score:  0.875 \t Record:  (0.97957808, -0.0036768208, -0.014643032)\n",
      "Date:  2018-10-25 01:56:33 \t Anomaly Score:  0.625 \t Record:  (0.94449598, 0.066332854, -0.012572837)\n",
      "Date:  2018-10-26 06:06:14 \t Anomaly Score:  0.675 \t Record:  (1.0747079, -0.19165544, -0.019125551)\n",
      "Date:  2018-10-26 06:06:17 \t Anomaly Score:  1.0 \t Record:  (1.0876569, -0.19771799, -0.02243204)\n",
      "Date:  2018-10-26 06:06:20 \t Anomaly Score:  1.0 \t Record:  (1.0177127, -0.060836125, -0.021520209)\n",
      "Date:  2018-10-26 06:06:23 \t Anomaly Score:  0.925 \t Record:  (0.90547872, 0.14966409, -0.010893071)\n",
      "Date:  2018-10-26 06:06:26 \t Anomaly Score:  1.0 \t Record:  (0.97846556, 0.00055623631, -0.015026765)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    inputFilePath = '/media/tpc2/DATA/ProcessedLanceData/pepa_acc_timestep3.csv'\n",
    "    \n",
    "    scalarEncoder1Args = {\n",
    "      \"w\": 21,\n",
    "      \"minval\": 0.9,\n",
    "      \"maxval\": 1.0,\n",
    "      \"periodic\": False,\n",
    "      \"n\": 50,\n",
    "      \"radius\": 0,\n",
    "      \"resolution\": 0,\n",
    "      \"name\": \"pepa_acc_x\",\n",
    "      \"verbosity\": 0,\n",
    "      \"clipInput\": True,\n",
    "      \"forced\": False,\n",
    "    }\n",
    "    \n",
    "    scalarEncoder2Args = {\n",
    "      \"w\": 21,\n",
    "      \"minval\": -0.1,\n",
    "      \"maxval\": 0.1,\n",
    "      \"periodic\": False,\n",
    "      \"n\": 50,\n",
    "      \"radius\": 0,\n",
    "      \"resolution\": 0,\n",
    "      \"name\": \"pepa_acc_y\",\n",
    "      \"verbosity\": 0,\n",
    "      \"clipInput\": True,\n",
    "      \"forced\": False,\n",
    "    }\n",
    "\n",
    "    scalarEncoder3Args = {\n",
    "      \"w\": 21,\n",
    "      \"minval\": -0.1,\n",
    "      \"maxval\": 0.1,\n",
    "      \"periodic\": False,\n",
    "      \"n\": 50,\n",
    "      \"radius\": 0,\n",
    "      \"resolution\": 0,\n",
    "      \"name\": \"pepa_acc_z\",\n",
    "      \"verbosity\": 0,\n",
    "      \"clipInput\": True,\n",
    "      \"forced\": False,\n",
    "    }\n",
    "    \n",
    "    dateEncoderArgs = {\n",
    "      \"season\": 0,\n",
    "      \"dayOfWeek\": 0,\n",
    "      \"weekend\": 0,\n",
    "      \"holiday\": 0,\n",
    "      \"timeOfDay\": (21, 1),\n",
    "      \"customDays\": 0,\n",
    "      \"name\": \"time\",\n",
    "      \"forced\": False\n",
    "    }\n",
    "\n",
    "    recordParams = {\n",
    "      \"inputFilePath\": inputFilePath,\n",
    "      \"scalarEncoder1Args\": scalarEncoder1Args,\n",
    "      \"scalarEncoder2Args\": scalarEncoder2Args,\n",
    "      \"scalarEncoder3Args\": scalarEncoder3Args,\n",
    "      \"dateEncoderArgs\": dateEncoderArgs,\n",
    "    }\n",
    "\n",
    "    network = createTemporalAnomaly(recordParams)\n",
    "    date = getDate(recordParams, _NUM_RECORDS)\n",
    "    runNetwork(network, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
